```
1. list the your  instances by ip adress and dns name(4)
2. list the linux release you are using(2)
3. list the file system capacity for the first node(master node)(2)
4. list the command and output for yum repolist enabled(4)
5. create user training and group skcc(4)
6. list output of the flowing commands : getent group skcc/ passwd training(4)
```

```
7. a command and output that shows the hostname of your database server(5)
8. a command and output taht reports the dataase server version(5)
9. a command and output that lists all the databases in the server(5)
10. download jdbc connector and jdk on each nodes(5)
11. make sure that the following services(hdfs/yarn/sqoop/hive/impala/hue)(5)
```

```
12. in you cluster, create a user named "training" with password "training"(4)
13. create table author and posts(4)
14. create grant user "training" with password "training" full access to the tables(4)
15. create author and posts directories in your home directory(4)
16. import both tables to hive using sqoop to hdfs directories(user/training)(4)
17. create authors as ac external table(4)
18. create posts as managed table(4)
19. create the table "results"that satisfiy the folowwing conditions in 4-b(4)
20. save the output as file under your home directory with name 'results'(4)
21. create a mysql table 'results' and export the data in hdfs result diretory to the table(4) 
```
